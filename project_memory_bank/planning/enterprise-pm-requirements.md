---
name: Enterprise PM Requirements
description: Pain points, data requirements, and implementation architecture for AI product managers
last_updated: 2025-12-19
status: active
---

# Enterprise PM Requirements

## ðŸ“‹ Project Status: Phases 1â€“3 [VERIFIED]

The foundation of the Enterprise Decision Hub is complete.

| Phase | Milestone | Status | Key Deliverable |
| :--- | :--- | :--- | :--- |
| **Phase 1** | **Data Foundation** | âœ… | Automated HF Pipeline + NVIDIA/Huawei JSONs |
| **Phase 2** | **Reference Pages** | âœ… | Model Explorer + Hardware Hub + Vendor Pages |
| **Phase 3** | **Navigation Hub** | âœ… | Sticky Global Nav + Ecosystem Grid + Contextual Links |

## ðŸŽ¯ Current Focus: Phase 4 â€” Visual Insights & Workload Modeling

### 1. Multi-GPU Topology Visualizations
*   **Need**: Users need to understand the impact of inter-GPU communication.
*   **Plan**: SVG diagrams for **NVLink Mesh (8Ã— H100)** vs **PCIe Tree**.
*   **Logic**: Illustrate why "8Ã— cards" is better than "2Ã— nodes of 4Ã— cards" for massive models.

### 2. Workload Calculator Mode
*   **Need**: PMs start with business requirements (Users), not technical ones (Batch Size).
*   **Plan**: Section: "Users Ã— Requests/min Ã— Avg tokens = Throughput (tokens/sec)".
*   **Outcome**: Auto-populate the "Speed (tokens/sec)" input based on business scale.

### 3. Capacity Validation (Stress Testing)
*   **Need**: "Can 4Ã— H100 handle 50 concurrent users?"
*   **Plan**: Calculate memory pressure and latency degradation under high batch sizes.

## ðŸš§ Known Issues & Refinements
*   **Llama 3.1 405B**: Automated config fetch fails due to Meta's license gate (HTTP 401). Requires manual metadata override.
*   **Mobile UI**: Large comparison tables in the Hardware Hub need horizontal scroll optimizations.
*   **i18n Coverage**: Ensure model-specific tooltips are fully translated in Chinese mode.

## ðŸš€ Future Roadmap (Phase 5)
*   **RFP Spec Generator**: Export PDF with calculated hardware requirements for vendor bidding.
*   **Benchmarking Database**: Integrate real-world throughput data from vLLM/TensorRT-LLM community reports.
