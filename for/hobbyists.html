<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Check if your RTX 4090, 3090, or Mac can run Llama, Mistral, Qwen, or other open LLMs locally. Free offline calculator for gamers and hobbyists.">
  <meta name="keywords" content="run LLM locally, GPU requirements, RTX 4090 LLM, Mac LLM, gaming GPU AI">
  <meta property="og:title" content="Can Your GPU Run This LLM? | LLM Resource Sizer">
  <meta property="og:description" content="Find out if your gaming GPU or Mac can run the latest open-source LLMs‚Äîbefore you download.">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://llmrunnable.com/for/hobbyists">
  <title>Can Your GPU Run This LLM? | LLM Resource Sizer</title>
  <link rel="stylesheet" href="../css/main.css">
</head>
<body>
  <nav class="global-nav">
    <a href="../" class="nav-brand">
      <span class="nav-icon">üßÆ</span>
      <span class="nav-logo">LLM Sizer</span>
    </a>
    <button class="mobile-menu-toggle" aria-label="Toggle menu">‚ò∞</button>
    <div class="nav-links" id="navLinks">
      <a href="../" class="nav-item">Models</a>
      <a href="../calculator.html" class="nav-item">Calculator</a>
      <a href="../hardware/" class="nav-item">Hardware</a>
      <a href="../for/enterprise.html" class="nav-item active">Guides</a>
    </div>
    <div class="nav-actions">
      <label class="field compact language-switch" style="margin-bottom: 0;">
        <select id="langSelect" disabled style="opacity: 0.5; cursor: not-allowed;" title="Translation coming soon">
          <option value="en">English</option>
        </select>
      </label>
    </div>
  </nav>

  <header class="hero" style="border-bottom: none;">
    <div class="header-content">
      <h1 class="hero-title">Can your GPU run it?</h1>
      <p class="lede">Quick checks for common models on consumer hardware</p>
    </div>
  </header>
  
  <section class="landing-section">
    <div class="landing-grid">
      <a href="/?preset=llama-3-8b&mode=local&prompt=8000&new=1000#calculator" class="card-landing">
        <h3>Llama 3.1 8B on RTX 4090</h3>
        <p>Can a single 4090 run Meta's 8B model with long context?</p>
      </a>
      <a href="/?preset=qwen-2.5-32b&mode=local&prompt=10000#calculator" class="card-landing">
        <h3>Qwen 2.5 32B on Mac Studio</h3>
        <p>Does the M2 Ultra have enough unified memory for Qwen?</p>
      </a>
      <a href="/?preset=deepseek-v3&mode=local&prompt=5000#calculator" class="card-landing">
        <h3>DeepSeek-V3 on RTX 3090</h3>
        <p>Can last-gen consumer hardware handle a 671B MoE?</p>
      </a>
      <a href="/?preset=llama-3-70b&mode=local&prompt=4000#calculator" class="card-landing">
        <h3>Llama 3 70B quantized</h3>
        <p>How much VRAM for 70B with INT4 quantization?</p>
      </a>
      <a href="/?preset=mistral-7b&mode=local&prompt=16000#calculator" class="card-landing">
        <h3>Mistral 7B with 16K context</h3>
        <p>Check long-context support on mid-range GPUs.</p>
      </a>
      <a href="/?preset=phi-3.5-mini&mode=local&prompt=3000#calculator" class="card-landing">
        <h3>Phi-3.5 Mini on RTX 3080</h3>
        <p>Can a 10GB card handle Microsoft's efficient model?</p>
      </a>
    </div>
  </section>

  <footer style="max-width: 1240px; margin: 32px auto 40px; padding: 0 20px; text-align: center; color: var(--muted); font-size: 13px;">
    <a href="/" style="color: var(--accent); text-decoration: none; font-weight: 600;">‚Üê Back to calculator</a>
  </footer>

  <script src="../js/nav.js"></script>
</body>
</html>

