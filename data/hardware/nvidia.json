{
  "metadata": {
    "vendor": "NVIDIA",
    "updated_at": "2025-12-16",
    "curated_by": "Track A - Person 1",
    "source": "https://www.nvidia.com/en-us/data-center/",
    "version": "1.0.0",
    "note": "Specs compiled from official NVIDIA documentation. All values verified from product datasheets."
  },
  "hardware": [
    {
      "id": "nvidia-h100-sxm",
      "name": "H100 SXM",
      "type": "gpu",
      "generation": "Hopper",
      "vram_gb": 80,
      "memory_type": "HBM3",
      "bandwidth_gbps": 3350,
      "fp16_tflops": 1979,
      "bf16_tflops": 1979,
      "fp8_tflops": 3958,
      "int8_tops": 3958,
      "tdp_watts": 700,
      "form_factor": "SXM5",
      "interconnect": "NVLink 4.0",
      "interconnect_bandwidth_gbps": 900,
      "max_cards_per_node": 8,
      "release_year": 2022,
      "status": "available",
      "source_url": "https://www.nvidia.com/en-us/data-center/h100/",
      "verified_date": "2025-12-16"
    },
    {
      "id": "nvidia-h100-pcie",
      "name": "H100 PCIe",
      "type": "gpu",
      "generation": "Hopper",
      "vram_gb": 80,
      "memory_type": "HBM3",
      "bandwidth_gbps": 2000,
      "fp16_tflops": 1513,
      "bf16_tflops": 1513,
      "fp8_tflops": 3026,
      "int8_tops": 3026,
      "tdp_watts": 350,
      "form_factor": "PCIe Gen5",
      "interconnect": "PCIe 5.0 x16",
      "interconnect_bandwidth_gbps": 128,
      "max_cards_per_node": 8,
      "release_year": 2023,
      "status": "available",
      "source_url": "https://www.nvidia.com/en-us/data-center/h100/",
      "verified_date": "2025-12-16"
    },
    {
      "id": "nvidia-h200-sxm",
      "name": "H200 SXM",
      "type": "gpu",
      "generation": "Hopper",
      "vram_gb": 141,
      "memory_type": "HBM3e",
      "bandwidth_gbps": 4800,
      "fp16_tflops": 1979,
      "bf16_tflops": 1979,
      "fp8_tflops": 3958,
      "int8_tops": 3958,
      "tdp_watts": 700,
      "form_factor": "SXM5",
      "interconnect": "NVLink 4.0",
      "interconnect_bandwidth_gbps": 900,
      "max_cards_per_node": 8,
      "release_year": 2023,
      "status": "available",
      "source_url": "https://www.nvidia.com/en-us/data-center/h200/",
      "verified_date": "2025-12-16"
    },
    {
      "id": "nvidia-a100-sxm-80gb",
      "name": "A100 SXM 80GB",
      "type": "gpu",
      "generation": "Ampere",
      "vram_gb": 80,
      "memory_type": "HBM2e",
      "bandwidth_gbps": 2039,
      "fp16_tflops": 624,
      "bf16_tflops": 312,
      "fp32_tflops": 156,
      "int8_tops": 1248,
      "tdp_watts": 400,
      "form_factor": "SXM4",
      "interconnect": "NVLink 3.0",
      "interconnect_bandwidth_gbps": 600,
      "max_cards_per_node": 8,
      "release_year": 2020,
      "status": "available",
      "source_url": "https://www.nvidia.com/en-us/data-center/a100/",
      "verified_date": "2025-12-16"
    },
    {
      "id": "nvidia-a100-sxm-40gb",
      "name": "A100 SXM 40GB",
      "type": "gpu",
      "generation": "Ampere",
      "vram_gb": 40,
      "memory_type": "HBM2",
      "bandwidth_gbps": 1555,
      "fp16_tflops": 624,
      "bf16_tflops": 312,
      "fp32_tflops": 156,
      "int8_tops": 1248,
      "tdp_watts": 400,
      "form_factor": "SXM4",
      "interconnect": "NVLink 3.0",
      "interconnect_bandwidth_gbps": 600,
      "max_cards_per_node": 8,
      "release_year": 2020,
      "status": "available",
      "source_url": "https://www.nvidia.com/en-us/data-center/a100/",
      "verified_date": "2025-12-16"
    },
    {
      "id": "nvidia-a100-pcie-80gb",
      "name": "A100 PCIe 80GB",
      "type": "gpu",
      "generation": "Ampere",
      "vram_gb": 80,
      "memory_type": "HBM2e",
      "bandwidth_gbps": 1935,
      "fp16_tflops": 624,
      "bf16_tflops": 312,
      "fp32_tflops": 156,
      "int8_tops": 1248,
      "tdp_watts": 300,
      "form_factor": "PCIe Gen4",
      "interconnect": "PCIe 4.0 x16",
      "interconnect_bandwidth_gbps": 64,
      "max_cards_per_node": 8,
      "release_year": 2020,
      "status": "available",
      "source_url": "https://www.nvidia.com/en-us/data-center/a100/",
      "verified_date": "2025-12-16"
    },
    {
      "id": "nvidia-b100",
      "name": "B100",
      "type": "gpu",
      "generation": "Blackwell",
      "vram_gb": 192,
      "memory_type": "HBM3e",
      "bandwidth_gbps": 8000,
      "fp16_tflops": 3500,
      "bf16_tflops": 3500,
      "fp8_tflops": 7000,
      "fp4_tflops": 14000,
      "tdp_watts": 700,
      "form_factor": "SXM",
      "interconnect": "NVLink 5.0",
      "interconnect_bandwidth_gbps": 1800,
      "max_cards_per_node": 8,
      "release_year": 2024,
      "status": "announced",
      "source_url": "https://www.nvidia.com/en-us/data-center/b100/",
      "verified_date": "2025-12-16",
      "note": "Announced specs, availability TBD"
    },
    {
      "id": "nvidia-b200",
      "name": "B200",
      "type": "gpu",
      "generation": "Blackwell",
      "vram_gb": 192,
      "memory_type": "HBM3e",
      "bandwidth_gbps": 8000,
      "fp16_tflops": 4500,
      "bf16_tflops": 4500,
      "fp8_tflops": 9000,
      "fp4_tflops": 18000,
      "tdp_watts": 1000,
      "form_factor": "SXM",
      "interconnect": "NVLink 5.0",
      "interconnect_bandwidth_gbps": 1800,
      "max_cards_per_node": 8,
      "release_year": 2024,
      "status": "announced",
      "source_url": "https://www.nvidia.com/en-us/data-center/b200/",
      "verified_date": "2025-12-16",
      "note": "Announced specs, availability TBD"
    },
    {
      "id": "nvidia-gb200-nvl72",
      "name": "GB200 NVL72",
      "type": "gpu",
      "generation": "Blackwell",
      "vram_gb": 13824,
      "memory_type": "HBM3e",
      "bandwidth_gbps": 576000,
      "fp16_tflops": 324000,
      "bf16_tflops": 324000,
      "fp8_tflops": 648000,
      "fp4_tflops": 1296000,
      "tdp_watts": 120000,
      "form_factor": "Rack System",
      "interconnect": "NVLink 5.0",
      "interconnect_bandwidth_gbps": 129600,
      "max_cards_per_node": 72,
      "release_year": 2024,
      "status": "announced",
      "source_url": "https://www.nvidia.com/en-us/data-center/gb200-nvl72/",
      "verified_date": "2025-12-16",
      "note": "Full system with 72 GPUs, 36 Grace CPUs. Announced specs, availability TBD"
    }
  ]
}
